{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a88211b-6f48-4738-a56c-811b4693e415",
   "metadata": {},
   "source": [
    "BoxDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc458018-ee2e-4ced-961e-a3763afa1fa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#----------Github Link---------#\n",
    "https://github.com/showlab/BoxDiff\n",
    "\n",
    "#----------Code---------#\n",
    "!cd BoxDiff\n",
    "!pip install -r requirements.txt\n",
    "!git clone https://github.com/gligen/diffusers.git\n",
    "from diffusers import DiffusionPipeline\n",
    "pipeline = DiffusionPipeline.from_pretrained(\"gligen/gligen-generation-text-box\")\n",
    "\n",
    "#----------Error---------#\n",
    "#Not enough CUDA memory - resolution is to turn 1x32GB memory on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609c24ae-af0b-4860-809e-963ab1a58c10",
   "metadata": {},
   "source": [
    "Gligen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d262fd6-3725-42ae-86ff-3f5477e0844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#----------Github Link---------#\n",
    "https://github.com/gligen/GLIGEN\n",
    "\n",
    "#----------Code---------#\n",
    "cd GLIGEN\n",
    "python gligen_inference.py\n",
    "\n",
    "#----------Error---------#\n",
    "Model works - results in GLIGEN/generation_samples/generation_box_text\n",
    "Line 478 was modified so that we only use the Generation with box text image from GitHub 6.9GB Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8a3aa6-4d2c-411c-b549-44790eaad3e8",
   "metadata": {},
   "source": [
    "VisorGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed15bb6b-a845-420b-8fdd-36687ca083d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#----------Github Link---------#\n",
    "https://github.com/LLaVA-VL/LLaVA-Interactive-Demo\n",
    "\n",
    "#----------Code---------#\n",
    "# clone the repo\n",
    "git clone https://github.com/Sierkinhane/VisorGPT.git\n",
    "\n",
    "# go to directory\n",
    "cd VisorGPT\n",
    "\n",
    "# create a new environment\n",
    "conda create -n visorgpt python=3.8\n",
    "\n",
    "# activate the new environment\n",
    "conda activate visorgpt\n",
    "\n",
    "# prepare the basic environments\n",
    "pip3 install -r requirements.txt\n",
    "\n",
    "# install controlnet and gligen\n",
    "cd demo/ControlNet\n",
    "pip3 install -v -e .\n",
    "cd ../demo/GLIGEN\n",
    "pip3 install -v -e .\n",
    "\n",
    "#----------Error---------#\n",
    "#Errors in the requirements folder, depracted packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b959750b-65d5-4460-b3a3-c8962d176466",
   "metadata": {},
   "source": [
    "LLava-Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157cbcb0-cebd-4b5c-afac-4a0703940d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#----------Github Link---------#\n",
    "https://github.com/LLaVA-VL/LLaVA-Interactive-Demo\n",
    "\n",
    "#----------Code---------#\n",
    "git clone https://github.com/LLaVA-VL/LLaVA-Interactive-Demo.git\n",
    "conda create -n llava_int -c conda-forge -c pytorch python=3.10.8 pytorch=2.0.1 -y\n",
    "conda activate llava_int\n",
    "cd LLaVA-Interactive-Demo\n",
    "pip install -r requirements.txt\n",
    "source setup.sh\n",
    "#Run the demo\n",
    "#./run_demo.sh\n",
    "\n",
    "#----------Error---------#\n",
    "TO BE TESTED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8004c507-7a17-42ff-89b8-17125edd3c30",
   "metadata": {},
   "source": [
    "StableDiffusion CompVis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5552eae-75d1-40b3-96ca-0214fa423659",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#----------Github Link---------#\n",
    "https://huggingface.co/CompVis/stable-diffusion-v1-4\n",
    "\n",
    "#----------Code---------#\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "device = \"cuda\"\n",
    "\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "image = pipe(prompt).images[0]  \n",
    "    \n",
    "image.save(\"astronaut_rides_horse.png\")\n",
    "\n",
    "\n",
    "#----------Error---------#\n",
    "Working model but no bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014cf155-0fb6-4afc-aebb-f94a660168b7",
   "metadata": {},
   "source": [
    "Inpainting GLIGEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7696c11d-9a89-408b-84bf-9e01acbd317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#----------Github Link---------#\n",
    "https://huggingface.co/CompVis/stable-diffusion-v1-4\n",
    "\n",
    "#----------Code---------#\n",
    "import torch\n",
    "from diffusers import StableDiffusionGLIGENPipeline\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "# Insert objects described by text at the region defined by bounding boxes\n",
    "pipe = StableDiffusionGLIGENPipeline.from_pretrained(\n",
    "    \"masterful/gligen-1-4-inpainting-text-box\", variant=\"fp16\", torch_dtype=torch.float32\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "input_image = load_image(\n",
    "    \"https://hf.co/datasets/huggingface/documentation-images/resolve/main/diffusers/gligen/livingroom_modern.png\"\n",
    ")\n",
    "prompt = \"a blue ferrari and a waterfall\"\n",
    "boxes = [[0.2676, 0.6088, 0.4773, 0.7183],[0.4980, 0.4355, 0.8516, 0.7266]]\n",
    "phrases = [\"a blue ferrari\", \"a waterfall\"]\n",
    "\n",
    "images = pipe(\n",
    "    prompt=prompt,\n",
    "    gligen_phrases=phrases,\n",
    "    gligen_inpaint_image=input_image,\n",
    "    gligen_boxes=boxes,\n",
    "    gligen_scheduled_sampling_beta=1,\n",
    "    output_type=\"pil\",\n",
    "    num_inference_steps=50,\n",
    ").images\n",
    "\n",
    "images[0].save(\"./gligen-1-4-inpainting-text-box.jpg\")\n",
    "\n",
    "\n",
    "#----------Error---------#\n",
    "Working model with bounding box, but rubbish training"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu121.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cu121:m119"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
